{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_qlEty3XU3g",
        "outputId": "715bc3ea-d965-41c0-9070-e2b75d94d1c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYY0-cNKXpXy"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "prediction_directory = Path(\"/content/drive/MyDrive/runi_nlp/nlp-project/models-eden\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfMGVLtUX-Kp"
      },
      "outputs": [],
      "source": [
        "pred_files = list(prediction_directory.glob('*eval-preds*.json'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOzbhLV_Ybee",
        "outputId": "799828f6-0830-4e05-c4d2-bf6e0adc8cd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['plbart-trans-75-1-15-ep-eval-preds-0',\n",
              " 'plbart-trans-1-ep-eval-preds-0',\n",
              " 'codet5-base-trans-80-1-1-ep-eval-preds-0',\n",
              " 'codet5-base-trans-1-0-0-ep-eval-preds-0',\n",
              " 'plbart-trans-80-1-1-ep-eval-preds-0',\n",
              " 'codet5-base-half-train-data-trans-80-1-1-ep-eval-preds-0',\n",
              " 'plbart-half-data-trans-1-0-0-ep-eval-preds-0 (1)',\n",
              " 'plbart-half-data-trans-80-10-10-200-ep-eval-preds-0',\n",
              " 'codet5-small-trans-functions-concat-80-10-10-ep-eval-preds-0',\n",
              " 'codet5-1-eval-preds']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[x.stem for x in pred_files]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4naYBN7LaH6X",
        "outputId": "e0cdd3ad-b57d-4721-9033-0df1b21ce3da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting codebleu\n",
            "  Downloading codebleu-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tree-sitter<1.0.0,>=0.20.0 (from codebleu)\n",
            "  Downloading tree_sitter-0.20.1.tar.gz (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.2/126.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tree-sitter\n",
            "  Building wheel for tree-sitter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tree-sitter: filename=tree_sitter-0.20.1-cp310-cp310-linux_x86_64.whl size=424714 sha256=af1b33894c51db16ad1a342bf846588602ee34dbe7f7dfae47b9ed45ade424e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/d0/7a/a108b30f6615a71ca3a07ced1b149509d437a60c9d64820723\n",
            "Successfully built tree-sitter\n",
            "Installing collected packages: tree-sitter, codebleu\n",
            "Successfully installed codebleu-0.2.1 tree-sitter-0.20.1\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.1.0-py3-none-any.whl (761 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.3/761.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.9.0 torchmetrics-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install codebleu\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFpqLy89ckWB"
      },
      "outputs": [],
      "source": [
        "def python_program_parser(python_densed: str) -> str:\n",
        "    \"\"\"This function will take a densed python code and parse it back to normal python representation.\"\"\"\n",
        "\n",
        "    # Constants\n",
        "    INDENT_TOKEN = \"INDENT\"\n",
        "    DEDENT_TOKEN = \"DEDENT\"\n",
        "    NEW_LINE_TOKEN = \"NEW_LINE\"\n",
        "    INDENT_SIZE = 4\n",
        "    PUNCTUATIONS = set(\"()[]{}:.,;+-*/%&|^<>=\")\n",
        "\n",
        "    # Split by space\n",
        "    tokens = python_densed.split()\n",
        "\n",
        "    # Initialize\n",
        "    lines = [[]]\n",
        "    current_indent = 0\n",
        "\n",
        "    for token in tokens:\n",
        "        if token == NEW_LINE_TOKEN:\n",
        "            lines.append([])  # Start a new line\n",
        "        elif token == INDENT_TOKEN:\n",
        "            current_indent += 1\n",
        "            lines[-1].extend([' ' * (current_indent * INDENT_SIZE)])  # Add the current indentation\n",
        "        elif token == DEDENT_TOKEN:\n",
        "            current_indent -= 1\n",
        "            lines[-1].extend([' ' * (current_indent * INDENT_SIZE)])  # Add the current indentation\n",
        "        else:\n",
        "            if lines[-1] and lines[-1][-1] not in PUNCTUATIONS and token not in PUNCTUATIONS:\n",
        "                lines[-1].append(' ')\n",
        "            lines[-1].append(token)\n",
        "\n",
        "    # Construct the final result\n",
        "    result = '\\n'.join([''.join(line) for line in lines])\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptPnWKGhYh2I",
        "outputId": "aa8fbe15-daa7-4a5a-dab1-c7ce5b9ee28a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics for: plbart-trans-75-1-15-ep-eval-preds-0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3938/3938 [04:32<00:00, 14.46it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics for: plbart-trans-1-ep-eval-preds-0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3938/3938 [04:44<00:00, 13.85it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics for: codet5-base-trans-80-1-1-ep-eval-preds-0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3938/3938 [03:53<00:00, 16.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics for: codet5-base-trans-1-0-0-ep-eval-preds-0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3938/3938 [04:23<00:00, 14.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics for: plbart-trans-80-1-1-ep-eval-preds-0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3938/3938 [05:19<00:00, 12.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics for: codet5-base-half-train-data-trans-80-1-1-ep-eval-preds-0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3938/3938 [05:13<00:00, 12.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics for: plbart-half-data-trans-1-0-0-ep-eval-preds-0 (1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3938/3938 [05:43<00:00, 11.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics for: plbart-half-data-trans-80-10-10-200-ep-eval-preds-0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3938/3938 [05:10<00:00, 12.70it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics for: codet5-small-trans-functions-concat-80-10-10-ep-eval-preds-0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 480/480 [1:09:20<00:00,  8.67s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics for: codet5-1-eval-preds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3938/3938 [04:58<00:00, 13.18it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from codebleu import calc_codebleu\n",
        "from torchmetrics.text import BLEUScore, MatchErrorRate, CharErrorRate, TranslationEditRate, SacreBLEUScore\n",
        "from torchmetrics.text.rouge import ROUGEScore\n",
        "from torchmetrics import MetricCollection\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "def compute_metrics(preds):\n",
        "    true_py = [p['python_t'] for p in preds]\n",
        "    pred_py = [p['python_p'] for p in preds]\n",
        "\n",
        "    bleu = BLEUScore()\n",
        "    sbleu = SacreBLEUScore()\n",
        "    ter = TranslationEditRate()\n",
        "\n",
        "    rouge = ROUGEScore()\n",
        "    mer = MatchErrorRate()\n",
        "    cer = CharErrorRate()\n",
        "\n",
        "    metrics_a = MetricCollection(bleu,sbleu,ter)\n",
        "    metrics_b = MetricCollection(rouge,mer,cer)\n",
        "\n",
        "    for p in tqdm(preds):\n",
        "        metrics_a.update([p['python_p']], [[p['python_t']]])\n",
        "        metrics_b.update(p['python_p'], p['python_t'])\n",
        "\n",
        "    # metrics_a.plot(together=True)\n",
        "    # metrics_b.plot(together=True)\n",
        "\n",
        "    return metrics_a.compute(), metrics_b.compute(), calc_codebleu(true_py,pred_py, lang=\"python\", weights=(0.25, 0.25, 0.25, 0.25), tokenizer=None)\n",
        "\n",
        "model_metrics = {}\n",
        "for pf in pred_files:\n",
        "  with pf.open(\"r\") as f:\n",
        "      eval_preds = json.load(f)\n",
        "      print(f'Calculating metrics for: {pf.stem}')\n",
        "      v_m_a, v_m_b, v_codebleu = compute_metrics(eval_preds)\n",
        "      model_metrics[pf.stem] = {\n",
        "          'v_m_a': v_m_a,\n",
        "          'v_m_b': v_m_b,\n",
        "          'v_codebleu': v_codebleu\n",
        "      }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASWFmbxSepkI",
        "outputId": "0eb13396-218a-405f-9f11-e8b5a9fe04ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics for: codet5-1-eval-preds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 12/3938 [00:00<00:34, 115.02it/s]"
          ]
        }
      ],
      "source": [
        "pf = pred_files[-1]\n",
        "with pf.open(\"r\") as f:\n",
        "    eval_preds = json.load(f)\n",
        "    print(f'Calculating metrics for: {pf.stem}')\n",
        "    v_m_a, v_m_b, v_codebleu = compute_metrics(eval_preds)\n",
        "    model_metrics[pf.stem] = {\n",
        "        'v_m_a': v_m_a,\n",
        "        'v_m_b': v_m_b,\n",
        "        'v_codebleu': v_codebleu\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iX8Y9i-0b9ac"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pandas_results = []\n",
        "for k, v in model_metrics.items():\n",
        "  results_row = {'model': k}\n",
        "  for sk, sv in v['v_m_a'].items():\n",
        "    results_row[sk] = sv.item()\n",
        "\n",
        "  for sk, sv in v['v_m_b'].items():\n",
        "    results_row[sk] = sv.item()\n",
        "\n",
        "  for sk, sv in v['v_codebleu'].items():\n",
        "    results_row[sk] = sv\n",
        "\n",
        "  pandas_results.append(results_row)\n",
        "\n",
        "df = pd.DataFrame(pandas_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCsEmtH6eUmB"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faCkVaLiYwvB"
      },
      "outputs": [],
      "source": [
        "csv_path = \"/content/drive/MyDrive/runi_nlp/nlp-project/model_metrics_2.csv\"\n",
        "df.to_csv(csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAk-BHxdb7w1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}